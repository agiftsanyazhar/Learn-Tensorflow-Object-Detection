{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: albumentations in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (1.4.7)\n",
      "Collecting numpy>=1.24.4 (from albumentations)\n",
      "  Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: scipy>=1.10.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from albumentations) (1.10.1)\n",
      "Requirement already satisfied: scikit-image>=0.21.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from albumentations) (0.21.0)\n",
      "Requirement already satisfied: PyYAML in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from albumentations) (6.0.1)\n",
      "Collecting typing-extensions>=4.9.0 (from albumentations)\n",
      "  Using cached typing_extensions-4.11.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: scikit-learn>=1.3.2 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from albumentations) (1.3.2)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from albumentations) (2.7.1)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from albumentations) (4.9.0.80)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from pydantic>=2.7.0->albumentations) (2.18.2)\n",
      "Requirement already satisfied: networkx>=2.8 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (3.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.27 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2.34.1)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (1.4.1)\n",
      "Requirement already satisfied: packaging>=21 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (24.0)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-image>=0.21.0->albumentations) (0.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from scikit-learn>=1.3.2->albumentations) (3.5.0)\n",
      "Using cached numpy-1.24.4-cp38-cp38-win_amd64.whl (14.9 MB)\n",
      "Using cached typing_extensions-4.11.0-py3-none-any.whl (34 kB)\n",
      "Installing collected packages: typing-extensions, numpy\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "Successfully installed numpy-1.24.4 typing-extensions-4.11.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'F:\\Tutorial\\learn-tensorflow-object-detection\\.venv\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "object-detection 0.1 requires apache-beam, which is not installed.\n",
      "object-detection 0.1 requires avro-python3, which is not installed.\n",
      "object-detection 0.1 requires contextlib2, which is not installed.\n",
      "object-detection 0.1 requires Cython, which is not installed.\n",
      "object-detection 0.1 requires lvis, which is not installed.\n",
      "object-detection 0.1 requires pandas, which is not installed.\n",
      "object-detection 0.1 requires pycocotools, which is not installed.\n",
      "sacrebleu 2.2.0 requires portalocker, which is not installed.\n",
      "sacrebleu 2.2.0 requires regex, which is not installed.\n",
      "sacrebleu 2.2.0 requires tabulate>=0.8.9, which is not installed.\n",
      "tf-models-official 2.16.0 requires Cython, which is not installed.\n",
      "tf-models-official 2.16.0 requires gin-config, which is not installed.\n",
      "tf-models-official 2.16.0 requires google-api-python-client>=1.6.7, which is not installed.\n",
      "tf-models-official 2.16.0 requires immutabledict, which is not installed.\n",
      "tf-models-official 2.16.0 requires kaggle>=1.3.9, which is not installed.\n",
      "tf-models-official 2.16.0 requires oauth2client, which is not installed.\n",
      "tf-models-official 2.16.0 requires pandas>=0.22.0, which is not installed.\n",
      "tf-models-official 2.16.0 requires py-cpuinfo>=3.3.0, which is not installed.\n",
      "tf-models-official 2.16.0 requires pycocotools, which is not installed.\n",
      "tf-models-official 2.16.0 requires sentencepiece, which is not installed.\n",
      "tf-models-official 2.16.0 requires seqeval, which is not installed.\n",
      "tf-models-official 2.16.0 requires tensorflow-datasets, which is not installed.\n",
      "tf-models-official 2.16.0 requires tensorflow-hub>=0.6.0, which is not installed.\n",
      "tf-models-official 2.16.0 requires tensorflow-model-optimization>=0.4.1, which is not installed.\n",
      "tf-models-official 2.16.0 requires tensorflow-text~=2.16.1, which is not installed.\n",
      "tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.8.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires numpy<=1.24.3,>=1.22, but you have numpy 1.24.4 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires tensorboard<2.14,>=2.13, but you have tensorboard 2.8.0 which is incompatible.\n",
      "tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.11.0 which is incompatible.\n",
      "object-detection 0.1 requires pyparsing==2.4.7, but you have pyparsing 3.1.2 which is incompatible.\n",
      "tf-models-official 2.16.0 requires tensorflow~=2.16.1, but you have tensorflow 2.8.0 which is incompatible.\n",
      "tf-models-official 2.16.0 requires tf-keras>=2.16.0, but you have tf-keras 2.15.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: filelock in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from torch) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in f:\\tutorial\\learn-tensorflow-object-detection\\.venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to parse XML files and extract bounding boxes\n",
    "def parse_voc_xml(xml_file):\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    boxes = []\n",
    "    for member in root.findall(\"object\"):\n",
    "        xmin = int(member.find(\"bndbox\").find(\"xmin\").text)\n",
    "        ymin = int(member.find(\"bndbox\").find(\"ymin\").text)\n",
    "        xmax = int(member.find(\"bndbox\").find(\"xmax\").text)\n",
    "        ymax = int(member.find(\"bndbox\").find(\"ymax\").text)\n",
    "        boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "    return boxes, tree\n",
    "\n",
    "\n",
    "# Define the augmentation pipeline\n",
    "transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=350, width=350),\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"pascal_voc\", label_fields=[\"class_labels\"]),\n",
    ")\n",
    "\n",
    "\n",
    "# Function to process a single image and its XML annotation\n",
    "def process_image(image_path, xml_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Parse the XML file to get bounding boxes\n",
    "    boxes, tree = parse_voc_xml(xml_path)\n",
    "    class_labels = [0] * len(boxes)  # Replace with actual class labels if available\n",
    "\n",
    "    # Apply the augmentation\n",
    "    transformed = transform(image=image, bboxes=boxes, class_labels=class_labels)\n",
    "\n",
    "    transformed_image = transformed[\"image\"]\n",
    "    transformed_bboxes = transformed[\"bboxes\"]\n",
    "\n",
    "    # Save the augmented image and create a new XML file with the updated bounding boxes\n",
    "    augmented_image_path = image_path.replace(\"images\", \"augmented_images\")\n",
    "    augmented_xml_path = xml_path.replace(\"images\", \"augmented_images\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(augmented_image_path), exist_ok=True)\n",
    "\n",
    "    cv2.imwrite(augmented_image_path, transformed_image)\n",
    "\n",
    "    create_augmented_xml(augmented_xml_path, transformed_bboxes, tree)\n",
    "\n",
    "\n",
    "# Function to create a new XML file with updated bounding boxes\n",
    "def create_augmented_xml(xml_path, bboxes, original_tree):\n",
    "    root = original_tree.getroot()\n",
    "\n",
    "    for i, member in enumerate(root.findall(\"object\")):\n",
    "        bbox = member.find(\"bndbox\")\n",
    "        bbox.find(\"xmin\").text = str(bboxes[i][0])\n",
    "        bbox.find(\"ymin\").text = str(bboxes[i][1])\n",
    "        bbox.find(\"xmax\").text = str(bboxes[i][2])\n",
    "        bbox.find(\"ymax\").text = str(bboxes[i][3])\n",
    "\n",
    "    original_tree.write(xml_path)\n",
    "\n",
    "\n",
    "# Traverse directories and process images\n",
    "base_dir = \"Tensorflow/workspace/images/collectedimages\"\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(root, file)\n",
    "            xml_path = image_path.replace(\".jpg\", \".xml\")\n",
    "\n",
    "            if os.path.exists(xml_path):\n",
    "                process_image(image_path, xml_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
